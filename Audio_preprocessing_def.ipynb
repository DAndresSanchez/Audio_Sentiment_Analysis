{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of audio files for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read, write\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "# Calculate Energy\n",
    "def energy_calc(signal: np.array, segment_length: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculates energy of the audio segment. Normalised with segment legth.\n",
    "    \"\"\"\n",
    "    energy = []\n",
    "    for i in range(int(len(signal)/segment_length)):\n",
    "        segment = signal[i*segment_length:(i+1)*segment_length]# try except error ...\n",
    "        energy.append(np.sum(np.square(segment)) / segment_length)\n",
    "        if energy[-1] < 0:\n",
    "            print(i)\n",
    "    return energy\n",
    "\n",
    "# Preprocess signal\n",
    "def preprocess_signal(filename: str, short_term_length:float=0.020, short_term_overlap:float=0,\\\n",
    "                      medium_term_length:float=1, medium_term_overlap:float=0.020) -> np.array:\n",
    "    \"\"\"\n",
    "    Preprocessing of the audiofile to get 28 coeficients after three steps:\n",
    "    - Short term analysis: segmentation of audio to get energy and 13 MFCCs per segment. \n",
    "    - Medium term analysis: segmentation of audio to get mean and standard deviation per segment.\n",
    "    - Long term analysis: mean of the medium term values per segment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import audio signal\n",
    "    sr, signal = read(filename)\n",
    "    \n",
    "    # Convert to 8kHz\n",
    "    sr_objective = 8000\n",
    "    sr_ratio = int(sr/sr_objective)\n",
    "    try:\n",
    "        signal = signal[::sr_ratio,0]\n",
    "    except IndexError:\n",
    "        signal = signal[::sr_ratio]\n",
    "    sr = sr_objective    \n",
    "\n",
    "    # Normalise\n",
    "    signal = signal.astype(np.float32)\n",
    "    signal = signal / np.abs(signal).max() / 2\n",
    "    \n",
    "    # Calculate length and define segments\n",
    "    length = len(signal)\n",
    "    length_s = length/sr # length of segment in seconds\n",
    "    short_term_length = 0.020 # s \n",
    "    short_term_overlap = 0 # s\n",
    "    medium_term_length = 1 # s \n",
    "    medium_term_overlap = 0.020 # s\n",
    "\n",
    "    # Convert to samples per segment\n",
    "    n_fft_st = int(length_s // (short_term_length - short_term_overlap))\n",
    "    hop_length_st = n_fft_st # no overlap\n",
    "    segment_length = n_fft_st\n",
    "    energy = np.array(energy_calc(signal, n_fft_st))\n",
    "    \n",
    "    # SHORT TERM ANALYSIS\n",
    "    # Calculate MFCCs for short term\n",
    "    mfcc_st = librosa.feature.mfcc(y=signal, sr=sr, n_fft=n_fft_st, n_mfcc=13, hop_length=hop_length_st)\n",
    "    mfcc_st = mfcc_st[:,:len(energy)]\n",
    "    coefficients_st = np.vstack((mfcc_st, energy))\n",
    "\n",
    "    \n",
    "    # MEDIUM TERM ANALYSIS\n",
    "    # Calculation of segments length for medium term analysis\n",
    "    n_segments_mt = int(length_s // (medium_term_length - medium_term_overlap))\n",
    "    n_fft_mt = int(coefficients_st.shape[1] * medium_term_length / length_s)\n",
    "    hop_length_mt = int(coefficients_st.shape[1] * (medium_term_length - medium_term_overlap) / length_s)     \n",
    "\n",
    "    # Calculation of parameters for medium term analysis\n",
    "    for i in range(n_segments_mt):\n",
    "        coefficient_i = coefficients_st[:, i*hop_length_mt:i*hop_length_mt+n_fft_mt]\n",
    "        mean_i = np.mean(coefficient_i, axis=1)\n",
    "        std_i = np.std(coefficient_i, axis=1)\n",
    "        if i == 0:\n",
    "            parameters_mt = np.hstack((mean_i, std_i))\n",
    "        else:\n",
    "            parameters_mt = np.row_stack((parameters_mt, np.hstack((mean_i, std_i))))\n",
    "\n",
    "    # LONG TERM ANALYSIS \n",
    "    # Calculation of parameters for long term analysis\n",
    "    if n_segments_mt > 1:\n",
    "        parameters_lt = np.mean(parameters_mt, axis=0)\n",
    "    else: \n",
    "        parameters_lt = parameters_mt\n",
    "\n",
    "    return parameters_lt\n",
    "\n",
    "# Get labels from directories\n",
    "def get_label(filename:str) -> str:\n",
    "    \"\"\"\n",
    "    Assign label from directory name.\n",
    "    \"\"\"\n",
    "    label = filename.split(\"/\")[-2]\n",
    "    return label\n",
    "\n",
    "# Merge characteristics and labels\n",
    "def add_label(filename:str) -> np.array:\n",
    "    \"\"\"\n",
    "    Add label to numpy array with 28 characteristics.\n",
    "    \"\"\"\n",
    "    coefficients = preprocess_signal(filename)\n",
    "    label = np.array(get_label(filename))\n",
    "    return np.hstack((coefficients, label))\n",
    "\n",
    "# Merge characteristics and labels from numpy arrays\n",
    "def add_label_arrays(x:np.array, y:np.array) -> np.array:\n",
    "    return np.hstack((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of one audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.93979321e+02, -1.69657067e+00,  1.91588197e+00,  1.73659050e+01,\n",
       "       -1.09046655e+01, -7.11656473e+00, -7.40737883e+00, -3.93999587e+00,\n",
       "       -7.61227444e+00, -5.92619336e+00,  1.35270376e+00, -6.45182750e+00,\n",
       "        7.49836474e-01,  3.15046834e-03,  8.84843322e+01,  5.13459678e+01,\n",
       "        2.41188476e+01,  1.39825992e+01,  1.71637517e+01,  1.37460917e+01,\n",
       "        1.33230337e+01,  8.69477242e+00,  1.04948500e+01,  9.86751072e+00,\n",
       "        1.00342119e+01,  9.80094698e+00,  9.08291644e+00,  4.23519576e-03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/happy/OAF_back_happy.wav'\n",
    "preprocess_signal(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-693.979321443582', '-1.696570674075356', '1.9158819657337816',\n",
       "       '17.365904977804497', '-10.904665450506572', '-7.116564728602579',\n",
       "       '-7.407378833505172', '-3.9399958698055415', '-7.612274439840377',\n",
       "       '-5.9261933575514', '1.3527037599418736', '-6.451827502891987',\n",
       "       '0.7498364737611029', '0.0031504683376025254', '88.48433222051601',\n",
       "       '51.345967795497096', '24.11884761473756', '13.982599152569499',\n",
       "       '17.163751667610406', '13.746091660038916', '13.323033704787505',\n",
       "       '8.694772417788025', '10.49484997040529', '9.867510722897586',\n",
       "       '10.034211872607441', '9.800946976442336', '9.0829164389685',\n",
       "       '0.004235195755367474', 'happy'], dtype='<U32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_label(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: data\n",
      "Directory: data/fear\n",
      "Directory: data/disgust\n",
      "Directory: data/happy\n",
      "Directory: data/sad\n",
      "Directory: data/neutral\n",
      "Directory: data/angry\n",
      "Directory: data/surprise\n"
     ]
    }
   ],
   "source": [
    "path = 'data'\n",
    "data = np.empty((29, 0))\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(path)):\n",
    "        print(f'Directory: {dirpath}')\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not path:\n",
    "            for file in filenames:\n",
    "                data_file = add_label(os.path.join(dirpath, file))\n",
    "                data = np.append(data, np.expand_dims(data_file, axis=1), axis=1)\n",
    "\n",
    "data = data.T\n",
    "np.savez('Sentiment_analysis_data', inputs=data[:,:28], targets=data[:,-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
